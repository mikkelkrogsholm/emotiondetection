{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "emotion detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Emotion detection using Spacy 3\n",
        "\n",
        "This notebook show how to do emotion detection on tweet size texts using a transformer architecture with Spacy 3.\n",
        "\n",
        "You can run this notebook on Google Colab if you want to customize it to your own needs. Remember to choose GPU hardware."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations and imports"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Installing Spacy library\n",
        "\n",
        "!pip install spacy==3.1.1\n",
        "!pip install spacy-transformers"
      ],
      "outputs": [],
      "metadata": {
        "id": "RUVIl0mAm9jw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Downloading the spaCy Transformer model \"en_core_web_trf\"\n",
        "!python -m spacy download en_core_web_trf"
      ],
      "outputs": [],
      "metadata": {
        "id": "5DgQgC4rnB3L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Importing libraries\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import spacy\n",
        "import spacy_transformers\n",
        "\n",
        "# Storing docs in binary format\n",
        "from spacy.tokens import DocBin"
      ],
      "outputs": [],
      "metadata": {
        "id": "TeGHiDDsnZge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read in the data\n",
        "\n",
        "I got the dataset from this github repository:\n",
        "https://github.com/RoozbehBandpey/ELTEA17"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Read in dataset\n",
        "\n",
        "jsonpath = \"sentence_level_annotation.json\"\n",
        "\n",
        "df = pd.read_json(jsonpath)\n",
        "\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>text</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>sent_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joy</td>\n",
              "      <td>That is one #happy #dog who never ceases to ma...</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sad</td>\n",
              "      <td>Because everyone knows Arsenal are desperate t...</td>\n",
              "      <td>S</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dis</td>\n",
              "      <td>You say that I'm paranoid but I'm pretty sure ...</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>joy</td>\n",
              "      <td>One of London's best days and showing the worl...</td>\n",
              "      <td>N</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sad</td>\n",
              "      <td>More children will die because govt not trying...</td>\n",
              "      <td>N</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  emotion                                               text sarcasm  sent_num\n",
              "0     joy  That is one #happy #dog who never ceases to ma...       N         1\n",
              "1     sad  Because everyone knows Arsenal are desperate t...       S         2\n",
              "2     dis  You say that I'm paranoid but I'm pretty sure ...       N         3\n",
              "3     joy  One of London's best days and showing the worl...       N         4\n",
              "4     sad  More children will die because govt not trying...       N         5"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HLqydEZfmoeB",
        "outputId": "f331192d-1e0d-43f1-cf78-68d5894f2196"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see there are a column with emotions and a column with the text. We are interested in those two.\n",
        "\n",
        "There are 6 different emotions, and I am interested in splitting the data into train and test sets, but keep the ratio across the emotions. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Splitting the dataset into train and test\n",
        "train = df.groupby(\"emotion\").sample(frac = 0.8, random_state = 25)\n",
        "test = df.drop(train.index)"
      ],
      "outputs": [],
      "metadata": {
        "id": "eWLp31WAmvr1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Checking the shape\n",
        "\n",
        "print(train.shape, test.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1626, 4) (408, 4)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_eBmoEtm2QP",
        "outputId": "7c5a2977-d9b6-4aa8-f985-a9353de72c69"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Creating tuples\n",
        "\n",
        "train['tuples'] = train.apply(lambda row : (row['text'],row['emotion']), axis=1)\n",
        "\n",
        "train = train['tuples'].tolist()\n",
        "\n",
        "test['tuples'] = test.apply(lambda row : (row['text'],row['emotion']), axis=1)\n",
        "\n",
        "test = test['tuples'].tolist()\n",
        "\n",
        "train[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"@GoDaddy This is your business model? You're part of the problem. #Shame\",\n",
              " 'ang')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7loEj3XoKgH",
        "outputId": "d6b4835b-ddea-48de-eb73-d4cd90044f3d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df.emotion.value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "joy    459\n",
              "sad    429\n",
              "dis    348\n",
              "sup    305\n",
              "fea    255\n",
              "ang    238\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufrgx8ZzoYZ6",
        "outputId": "e011ec4e-60b1-42ce-a7e1-b1b1b93f1406"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# User function for converting the train and test dataset into spaCy document\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_trf\")\n",
        "\n",
        "def document(data):\n",
        "#Creating empty list called \"text\"  \n",
        "\n",
        "    emotions = [\"joy\", \"sad\", \"dis\", \"sup\", \"fea\", \"ang\"]\n",
        "\n",
        "    text = []\n",
        "\n",
        "    for doc, label in nlp.pipe(data, as_tuples = True):\n",
        "\n",
        "        for emotion in emotions:\n",
        "            if (label == emotion):\n",
        "                doc.cats[emotion] = 1\n",
        "            else:\n",
        "                doc.cats[emotion] = 0\n",
        "    \n",
        "        #Adding the doc into the list 'text'\n",
        "        text.append(doc)\n",
        "        \n",
        "    return(text)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VcNcU41Iosz3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Calculate the time for converting into binary document for train dataset\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "#passing the train dataset into function 'document'\n",
        "train_docs = document(train)\n",
        "\n",
        "#Creating binary document using DocBin function in spaCy\n",
        "doc_bin = DocBin(docs = train_docs)\n",
        "\n",
        "#Saving the binary document as train.spacy\n",
        "doc_bin.to_disk(\"train.spacy\")\n",
        "end_time = datetime.now()\n",
        "\n",
        "#Printing the time duration for train dataset\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration: 0:03:07.909619\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8UB5ndTpgPk",
        "outputId": "75ac51ab-5f8c-44af-f8d1-21ff9dd999f1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Calculate the time for converting into binary document for test dataset\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "#passing the test dataset into function 'document'\n",
        "test_docs = document(test)\n",
        "doc_bin = DocBin(docs = test_docs)\n",
        "doc_bin.to_disk(\"test.spacy\")\n",
        "end_time = datetime.now()\n",
        "\n",
        "#Printing the time duration for test dataset\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration: 0:00:45.883531\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je9c4D5Bpuc-",
        "outputId": "0e5af7ab-b58c-4341-feec-aea48f2e2ba5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go here https://spacy.io/usage/training#quickstart\n",
        "\n",
        "And download the base_config.cfg\n",
        "\n",
        "Set it to:\n",
        "- textcat\n",
        "- gpu\n",
        "- accuracy\n",
        "\n",
        "Put it here. And then change the paths to:\n",
        "\n",
        "train = \"train.spacy\"\n",
        "\n",
        "dev = \"test.spacy\""
      ],
      "metadata": {
        "id": "a4EauO7Er-S0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Converting base configuration into full config file\n",
        "\n",
        "!python -m spacy init fill-config ./base_config.cfg ./config.cfg"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnQDOxKTpyBk",
        "outputId": "54217c52-9699-4b82-de99-e4dda8b03af4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Calculating the time for training the model\n",
        "start_time = datetime.now()\n",
        "\n",
        "# To train the model. Enabled GPU and storing the model output in folder called output_updated\n",
        "!python -m spacy train config.cfg --verbose  --gpu-id 0 --output ./output_updated\n",
        "\n",
        "end_time = datetime.now()\n",
        "\n",
        "#Printing the time taken for training the model\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: output_updated\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2021-09-30 07:45:38,058] [INFO] Set up nlp object from config\n",
            "[2021-09-30 07:45:38,071] [DEBUG] Loading corpus from path: test.spacy\n",
            "[2021-09-30 07:45:38,072] [DEBUG] Loading corpus from path: train.spacy\n",
            "[2021-09-30 07:45:38,073] [INFO] Pipeline: ['transformer', 'textcat']\n",
            "[2021-09-30 07:45:38,078] [INFO] Created vocabulary\n",
            "[2021-09-30 07:45:38,079] [INFO] Finished initializing nlp object\n",
            "Downloading: 100% 481/481 [00:00<00:00, 562kB/s]\n",
            "Downloading: 100% 899k/899k [00:00<00:00, 5.24MB/s]\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 4.06MB/s]\n",
            "Downloading: 100% 1.36M/1.36M [00:00<00:00, 8.50MB/s]\n",
            "Downloading: 100% 501M/501M [00:13<00:00, 37.2MB/s]\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2021-09-30 07:47:20,695] [INFO] Initialized pipeline components: ['transformer', 'textcat']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "[2021-09-30 07:47:20,708] [DEBUG] Loading corpus from path: test.spacy\n",
            "[2021-09-30 07:47:20,710] [DEBUG] Loading corpus from path: train.spacy\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'textcat']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE \n",
            "---  ------  -------------  ------------  ----------  ------\n",
            "  0       0           0.00          0.86        0.00    0.00\n",
            "  7     200           0.02         51.03       36.80    0.37\n",
            " 15     400           0.09         17.19       59.36    0.59\n",
            " 23     600           0.26          1.17       60.76    0.61\n",
            " 31     800           0.10          2.89       63.57    0.64\n",
            " 39    1000           0.02          0.05       62.32    0.62\n",
            " 47    1200           0.50          2.35       59.05    0.59\n",
            " 55    1400           0.03          0.20       61.72    0.62\n",
            " 63    1600           0.07          1.35       63.75    0.64\n",
            " 71    1800           0.01          0.03       61.31    0.61\n",
            " 79    2000           0.01          0.01       61.67    0.62\n",
            " 86    2200           0.00          0.00       59.41    0.59\n",
            " 94    2400           0.05          0.55       62.40    0.62\n",
            "102    2600           0.03          1.22       61.42    0.61\n",
            "110    2800           0.03          0.26       59.79    0.60\n",
            "118    3000           0.00          0.00       59.77    0.60\n",
            "126    3200           0.00          0.01       61.53    0.62\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output_updated/model-last\n",
            "Duration: 1:14:34.067607\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vDGXmnRqkla",
        "outputId": "296cbf5a-83f9-4a07-d1f1-84e810f0df92"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Testing the model\n",
        "\n",
        "# Loading the best model from output_updated folder\n",
        "nlp = spacy.load(\"output_updated/model-best\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "jkCs57V9tN6Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "text = \"Capitalism produces ecological crisis for the same reason it produces inequality: because the fundamental mechanism of capitalist growth is that capital must extract (from nature and labour) more than it gives in return.\"\n",
        "\n",
        "demo = nlp(text)\n",
        "\n",
        "a_dictionary = demo.cats\n",
        "cat = max(a_dictionary, key=a_dictionary.get)\n",
        "\n",
        "print(text)\n",
        "print(cat.upper())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Capitalism produces ecological crisis for the same reason it produces inequality: because the fundamental mechanism of capitalist growth is that capital must extract (from nature and labour) more than it gives in return.\n",
            "DIS\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwxKXST_tRLs",
        "outputId": "2c7044e1-05b4-4126-c243-63332004f67b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "a_dictionary"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ang': 0.0012292256578803062,\n",
              " 'dis': 0.9250048398971558,\n",
              " 'fea': 0.005434458144009113,\n",
              " 'joy': 0.0011282231425866485,\n",
              " 'sad': 0.06589248031377792,\n",
              " 'sup': 0.0013107025297358632}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOXYoD8x-tHp",
        "outputId": "2dad9843-f49f-4953-ecd4-6eb531583a50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store the stuff for faster reuse"
      ],
      "metadata": {
        "id": "yJIb1oK9-Rat"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZyjAhg17zuR",
        "outputId": "9e6a9b64-0a09-43f7-d5b3-faf088899393"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cp -r `ls -A | grep -v \"gdrive\"` /content/gdrive/MyDrive/emotions/"
      ],
      "outputs": [],
      "metadata": {
        "id": "-JtAlT3i94lb"
      }
    }
  ]
}